{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 4**"
      ],
      "metadata": {
        "id": "yF8vGNQOwxhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "WIMWk6RAWmJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "iayKQFnxWkWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blAX8_auX_Zr",
        "outputId": "db08caa7-e880-4f33-a88c-15742cc8e350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy"
      ],
      "metadata": {
        "id": "lThpTW0BZyqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "266e880c-c59c-4201-ee97-10ad8de8462f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "ZY1aG1DsYBYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "RJyOoei3YaCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load the data and Exploration**"
      ],
      "metadata": {
        "id": "yR1S49a0Wql-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"alaakhaled/conll003-englishversion\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print(\"Files in directory:\", os.listdir(path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVjNE51_Wjc_",
        "outputId": "8b2fa6e1-9615-4039-f68c-7a26954bbe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/alaakhaled/conll003-englishversion?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 960k/960k [00:00<00:00, 36.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/alaakhaled/conll003-englishversion/versions/1\n",
            "Files in directory: ['train.txt', 'test.txt', 'metadata', 'valid.txt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CoNLL-2003 train set\n",
        "file_path = os.path.join(path, 'train.txt')"
      ],
      "metadata": {
        "id": "mWC7l7k6W12c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse CoNLL-2003 file into entity-label format\n",
        "data = []\n",
        "with open(file_path, 'r') as f:\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            parts = line.split()\n",
        "            if len(parts) == 4:\n",
        "                word, pos, chunk, ner = parts\n",
        "                sentence.append({\"entity\": word, \"label\": ner})\n",
        "        else:\n",
        "            if sentence:\n",
        "                data.append(sentence)\n",
        "                sentence = []\n",
        "    if sentence:\n",
        "        data.append(sentence)\n",
        "\n",
        "print(f\"\\nLoaded {len(data)} sentences.\")\n",
        "print(\"Example sentence:\", data[0][:10])  # Show first 10 entity-label pairs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJKaXaW8W4LI",
        "outputId": "4c27acb9-9baf-42da-c37a-b8c12fe3206f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded 14987 sentences.\n",
            "Example sentence: [{'entity': '-DOCSTART-', 'label': 'O'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45081fdb"
      },
      "source": [
        "## **Rule-based NER**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rule_based_ner(sentence):\n",
        "    entities = []\n",
        "    for i, (word, ner) in enumerate(sentence):\n",
        "        # Rule: Capitalized words (not first in sentence) are entities\n",
        "        if word[0].isupper() and i != 0:\n",
        "            entities.append((word, \"POTENTIAL_ENTITY\"))\n",
        "    return entities"
      ],
      "metadata": {
        "id": "alDhtLX4W9I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = []\n",
        "for sentence in data:\n",
        "    processed_sentence = [(item[\"entity\"], item[\"label\"]) for item in sentence]\n",
        "    processed_data.append(processed_sentence)"
      ],
      "metadata": {
        "id": "GQSS1ff5CFYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in processed_data[:3]:\n",
        "    print(\"Sentence:\", sent)\n",
        "    print(\"Rule-based entities:\", rule_based_ner(sent))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYIvB6awXBsv",
        "outputId": "8518715c-bfb5-45c6-996b-c4f3d6a0c023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: [('-DOCSTART-', 'O')]\n",
            "Rule-based entities: []\n",
            "\n",
            "Sentence: [('EU', 'B-ORG'), ('rejects', 'O'), ('German', 'B-MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('British', 'B-MISC'), ('lamb', 'O'), ('.', 'O')]\n",
            "Rule-based entities: [('German', 'POTENTIAL_ENTITY'), ('British', 'POTENTIAL_ENTITY')]\n",
            "\n",
            "Sentence: [('Peter', 'B-PER'), ('Blackburn', 'I-PER')]\n",
            "Rule-based entities: [('Blackburn', 'POTENTIAL_ENTITY')]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9df920ef"
      },
      "source": [
        "## **Model-based NER (spaCy)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04bd8c63",
        "outputId": "d016f5bd-884b-493e-b231-475a4a1d381c"
      },
      "source": [
        "# Function to perform model-based NER\n",
        "def model_based_ner(sentence_tokens):\n",
        "    text = \" \".join([word for word, tag in sentence_tokens])\n",
        "    doc = nlp(text)\n",
        "    entities = []\n",
        "    for ent in doc.ents:\n",
        "        entities.append((ent.text, ent.label_))\n",
        "    return entities\n",
        "\n",
        "# Apply model-based NER to the first few processed sentences\n",
        "print(\"Model-based NER results for the first 5 sentences:\")\n",
        "for i, sent in enumerate(processed_data[:5]):\n",
        "    model_entities = model_based_ner(sent)\n",
        "    print(f\"Sentence {i+1}: {model_entities}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model-based NER results for the first 5 sentences:\n",
            "Sentence 1: []\n",
            "Sentence 2: [('EU', 'ORG'), ('German', 'NORP'), ('British', 'NORP')]\n",
            "Sentence 3: [('Peter Blackburn', 'PERSON')]\n",
            "Sentence 4: [('BRUSSELS', 'GPE'), ('1996-08-22', 'DATE')]\n",
            "Sentence 5: [('The European Commission', 'ORG'), ('Thursday', 'DATE'), ('German', 'NORP'), ('British', 'NORP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a114634"
      },
      "source": [
        "## **Highlight and categorize entities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "1e348d12",
        "outputId": "869b56f0-712d-470d-a303-efaafab79db6"
      },
      "source": [
        "def highlight_entities(sentence_tokens, entities):\n",
        "    text = \" \".join([word for word, tag in sentence_tokens])\n",
        "    html_text = text\n",
        "\n",
        "    # Sort entities by their order in text\n",
        "    sorted_entities = sorted(entities, key=lambda x: text.find(x[0]))\n",
        "\n",
        "    for entity_text, entity_type in sorted_entities:\n",
        "        html_text = html_text.replace(\n",
        "            entity_text,\n",
        "            f'<mark style=\"background-color: #FFD700\" data-entity=\"{entity_type}\">'\n",
        "            f'{entity_text} ({entity_type})</mark>'\n",
        "        )\n",
        "    return html_text\n",
        "\n",
        "# Example of highlighting using model-based NER results for the first 5 sentences\n",
        "print(\"Highlighted entities using Model-based NER:\")\n",
        "for i, sent in enumerate(processed_data[:5]):\n",
        "    model_entities = model_based_ner(sent)\n",
        "    highlighted_html = highlight_entities(sent, model_entities)\n",
        "    print(f\"Sentence {i+1}:\")\n",
        "    display(HTML(highlighted_html))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highlighted entities using Model-based NER:\n",
            "Sentence 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "-DOCSTART-"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark style=\"background-color: #FFD700\" data-entity=\"ORG\">EU (ORG)</mark> rejects <mark style=\"background-color: #FFD700\" data-entity=\"NORP\">German (NORP)</mark> call to boycott <mark style=\"background-color: #FFD700\" data-entity=\"NORP\">British (NORP)</mark> lamb ."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 3:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark style=\"background-color: #FFD700\" data-entity=\"PERSON\">Peter Blackburn (PERSON)</mark>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 4:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark style=\"background-color: #FFD700\" data-entity=\"GPE\">BRUSSELS (GPE)</mark> <mark style=\"background-color: #FFD700\" data-entity=\"DATE\">1996-08-22 (DATE)</mark>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 5:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<mark style=\"background-color: #FFD700\" data-entity=\"ORG\">The European Commission (ORG)</mark> said on <mark style=\"background-color: #FFD700\" data-entity=\"DATE\">Thursday (DATE)</mark> it disagreed with <mark style=\"background-color: #FFD700\" data-entity=\"NORP\">German (NORP)</mark> advice to consumers to shun <mark style=\"background-color: #FFD700\" data-entity=\"NORP\">British (NORP)</mark> lamb until scientists determine whether mad cow disease can be transmitted to sheep ."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bouns Task 4**"
      ],
      "metadata": {
        "id": "CCiEu61FY4Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load two spaCy models\n",
        "nlp_sm = spacy.load(\"en_core_web_sm\")\n",
        "nlp_md = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "1Or41fN5Z6xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_based_ner(sentence_tokens, nlp_model):\n",
        "    text = \" \".join([word for word, tag in sentence_tokens])\n",
        "    doc = nlp_model(text)\n",
        "    return doc"
      ],
      "metadata": {
        "id": "tK_SkwmfZ8YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick first 2 sentences for visualization\n",
        "sample_sentences = data[:2]\n",
        "\n",
        "print(\"\\nModel-based NER comparison:\")\n",
        "\n",
        "for i, sent in enumerate(sample_sentences):\n",
        "    print(f\"\\n----- Sentence {i+1} -----\")\n",
        "    text = \" \".join([w for w, t in sent])\n",
        "    print(\"Text:\", text)\n",
        "\n",
        "    # Small model\n",
        "    doc_sm = model_based_ner(sent, nlp_sm)\n",
        "    print(\"Entities (sm):\", [(ent.text, ent.label_) for ent in doc_sm.ents])\n",
        "\n",
        "    # Medium model\n",
        "    doc_md = model_based_ner(sent, nlp_md)\n",
        "    print(\"Entities (md):\", [(ent.text, ent.label_) for ent in doc_md.ents])\n",
        "\n",
        "    # Visualize with displaCy\n",
        "    print(\"\\nVisualization (sm):\")\n",
        "    displacy.render(doc_sm, style=\"ent\", jupyter=True)\n",
        "    print(\"\\nVisualization (md):\")\n",
        "    displacy.render(doc_md, style=\"ent\", jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTnI0CixZfg3",
        "outputId": "330afdb2-0967-46a0-a166-a80c948704b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model-based NER comparison:\n",
            "\n",
            "----- Sentence 1 -----\n",
            "Text: entity\n",
            "Entities (sm): []\n",
            "Entities (md): []\n",
            "\n",
            "Visualization (sm):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/spacy/displacy/__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  warnings.warn(Warnings.W006)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">entity</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Visualization (md):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">entity</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- Sentence 2 -----\n",
            "Text: entity entity entity entity entity entity entity entity entity\n",
            "Entities (sm): []\n",
            "Entities (md): []\n",
            "\n",
            "Visualization (sm):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">entity entity entity entity entity entity entity entity entity</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Visualization (md):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">entity entity entity entity entity entity entity entity entity</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}