{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 6**"
      ],
      "metadata": {
        "id": "tdj649yfjYAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "GxoFeaBEkmDo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "443e3dc4",
        "outputId": "f40bec75-603a-45bf-8c11-d1b143c4760e"
      },
      "source": [
        "%pip install evaluate -qq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m81.9/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "import evaluate # Import the evaluate library\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "QAcmi4LVkqEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load data and Exploration**"
      ],
      "metadata": {
        "id": "HbrSLMZqktfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"stanfordu/stanford-question-answering-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOj7i3Ewjr0v",
        "outputId": "e7a633ec-d1d3-49e8-de14-af596aefe521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/stanfordu/stanford-question-answering-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.73M/8.73M [00:00<00:00, 136MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/stanfordu/stanford-question-answering-dataset/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SQuAD v1.1 has JSON files (train-v1.1.json, dev-v1.1.json)\n",
        "train_file = os.path.join(path, \"train-v1.1.json\")\n",
        "dev_file = os.path.join(path, \"dev-v1.1.json\")"
      ],
      "metadata": {
        "id": "eqMOaA7ckzqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a few samples from dev set\n",
        "with open(dev_file, \"r\") as f:\n",
        "    squad_dev = json.load(f)\n",
        "\n",
        "examples = []\n",
        "for article in squad_dev[\"data\"][:2]:  # take first 2 articles for demo\n",
        "    for paragraph in article[\"paragraphs\"]:\n",
        "        context = paragraph[\"context\"]\n",
        "        for qa in paragraph[\"qas\"]:\n",
        "            question = qa[\"question\"]\n",
        "            answers = qa[\"answers\"]  # list of dicts with 'text' and 'answer_start'\n",
        "            examples.append({\"context\": context, \"question\": question, \"answers\": answers})"
      ],
      "metadata": {
        "id": "PlmQcr0ElRNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loaded {len(examples)} QA pairs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV4xsXe5oWAM",
        "outputId": "b8eba5d0-e414-4fa4-a860-34c5a65f4c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1057 QA pairs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Pretrained QA Model**"
      ],
      "metadata": {
        "id": "3vAb53iVoZF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased-distilled-squad\"  # small & fine-tuned for SQuAD\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "\n",
        "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e884a7a35d134006b10758996134f64d",
            "4b588cab2d4048678d9ee67739122159",
            "9ebab36c45224ddd8f973ef88efc4307",
            "5c0b69679de54ff0af741932a814d082",
            "41d949699609442c9ff3456d4bc91330",
            "494b9856dbb74268b19b95529127210f",
            "cb5584502f784353a2913ca60bf15f66",
            "76341685f9ba4867abecce4259f45452",
            "7b69152271d147c0bacd12902b557b8d",
            "d4d8299b4b37486ebe5b0f7d8d443934",
            "d5588747af6e4e25a7c54e086d8015fe",
            "c7eb327d744542e09e8bfd243d71a7e1",
            "21df3d4c150a40f38e1120f818b9b985",
            "1086053ded524d16884452d95276bf17",
            "f9129bf5f44448b08502a46a711d77f9",
            "e19393da3b9a47b1970aaaf236e03a1c",
            "3e611f26ff8b4748b01ba6db9a155b06",
            "301609ba53424a7593aa707adb8a2bad",
            "f9c20ef3dab24b81ab6f6f857da8b5de",
            "bda71dfb348d4014819eeaa99587e055",
            "04d18455df004746b51ee0b57e5864aa",
            "a19e48ab9097495db3a807a44a66cf06",
            "312997607ed74986b9064698362916df",
            "9e2380f2197f4072938af1873a39f877",
            "0051f68664d7498891155c7f22bbfd03",
            "2d9a171f9f794d58a24592408018d1c8",
            "647bd11619824dd5b9bf43292122bbb6",
            "2c59a65e69f145d4bcfd9ea2a3c75f66",
            "40a8c8b68b6645609fb430ce730e2381",
            "d21cfea6d4514a8c9d99531b3424a9cc",
            "047be26e1b3649fd8f1dd8b3085c210b",
            "431634b904d545c497817a43a2bb3bb7",
            "7f01a254f15c49e1b11e7151962fad12",
            "dcda168e7fc1413b9f390b4c2bed790b",
            "0bbd55d62abb4478990a9843d819f753",
            "3c5715f390ed43f78922d4b520e28897",
            "4ef7e9f7d56f467eb1d7956770546014",
            "aa3ba9684fa84034b49047f8fab433c9",
            "dd86f45e57324343880fa6e1bad5afc6",
            "01da014a0ecb4d24998304a3cdd2e9c2",
            "596f440352ec4352870c7171d2e5b7d0",
            "1a662091fd344a2693c83ee2eae4584f",
            "53d06d6ee5384056ab64b697e2b09fb7",
            "5ac8ee8f0e17408ebb1d6f44f4c28146",
            "3ad9b4cc46ba4834a8f32a50426b9465",
            "763b172d5592498184b2e93d582f46ae",
            "1d1ea03bf9744ed08fed48a495dff7b7",
            "cebcd4d366c949e4ab0e6dd890a9abe4",
            "c7ae2ec83af44903869a9385afda3e42",
            "029ac885e8c2490bb31d95653fb0cb1f",
            "eefa47759f1a40ff8bdba09742fa4b81",
            "1b7206ba2c114b609e6f8b93ce8837cf",
            "70f7857c3d52424f84b31966dd65fce3",
            "d8f42b12ae1941709bcf581df7d76443",
            "90bb4f96c2b342729f28a68cd2605ad2"
          ]
        },
        "id": "kW01XXEMoYzw",
        "outputId": "b1499932-6d97-44b3-af30-f8ca42a24ca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e884a7a35d134006b10758996134f64d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7eb327d744542e09e8bfd243d71a7e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "312997607ed74986b9064698362916df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcda168e7fc1413b9f390b4c2bed790b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ad9b4cc46ba4834a8f32a50426b9465"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run QA on Sample**"
      ],
      "metadata": {
        "id": "lTQLZcOXofd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Sample Predictions ---\")\n",
        "for ex in examples[:10]:\n",
        "    result = qa_pipeline(question=ex[\"question\"], context=ex[\"context\"])\n",
        "    print(f\"Q: {ex['question']}\")\n",
        "    print(f\"A (predicted): {result['answer']}\")\n",
        "    print(f\"A (true): {[a['text'] for a in ex['answers']]}\")\n",
        "    print(\"-\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzCaVFvlohEL",
        "outputId": "47f6202e-4bba-4039-805f-e639272e08cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample Predictions ---\n",
            "Q: Which NFL team represented the AFC at Super Bowl 50?\n",
            "A (predicted): Denver Broncos\n",
            "A (true): ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']\n",
            "------------------------------------------------------------\n",
            "Q: Which NFL team represented the NFC at Super Bowl 50?\n",
            "A (predicted): Carolina Panthers\n",
            "A (true): ['Carolina Panthers', 'Carolina Panthers', 'Carolina Panthers']\n",
            "------------------------------------------------------------\n",
            "Q: Where did Super Bowl 50 take place?\n",
            "A (predicted): Levi's Stadium\n",
            "A (true): ['Santa Clara, California', \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"]\n",
            "------------------------------------------------------------\n",
            "Q: Which NFL team won Super Bowl 50?\n",
            "A (predicted): Denver Broncos\n",
            "A (true): ['Denver Broncos', 'Denver Broncos', 'Denver Broncos']\n",
            "------------------------------------------------------------\n",
            "Q: What color was used to emphasize the 50th anniversary of the Super Bowl?\n",
            "A (predicted): gold\n",
            "A (true): ['gold', 'gold', 'gold']\n",
            "------------------------------------------------------------\n",
            "Q: What was the theme of Super Bowl 50?\n",
            "A (predicted): Arabic numerals\n",
            "A (true): ['\"golden anniversary\"', 'gold-themed', '\"golden anniversary']\n",
            "------------------------------------------------------------\n",
            "Q: What day was the game played on?\n",
            "A (predicted): February 7, 2016\n",
            "A (true): ['February 7, 2016', 'February 7', 'February 7, 2016']\n",
            "------------------------------------------------------------\n",
            "Q: What is the AFC short for?\n",
            "A (predicted): American Football Conference\n",
            "A (true): ['American Football Conference', 'American Football Conference', 'American Football Conference']\n",
            "------------------------------------------------------------\n",
            "Q: What was the theme of Super Bowl 50?\n",
            "A (predicted): Arabic numerals\n",
            "A (true): ['\"golden anniversary\"', 'gold-themed', 'gold']\n",
            "------------------------------------------------------------\n",
            "Q: What does AFC stand for?\n",
            "A (predicted): American Football Conference\n",
            "A (true): ['American Football Conference', 'American Football Conference', 'American Football Conference']\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluate with exact match and F1**"
      ],
      "metadata": {
        "id": "i573dtX5owdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"squad\")\n",
        "\n",
        "preds = []\n",
        "refs = []\n",
        "\n",
        "for ex in examples[:50]:  # evaluate on first 50 for speed\n",
        "    result = qa_pipeline(question=ex[\"question\"], context=ex[\"context\"])\n",
        "    preds.append({\"id\": ex[\"question\"], \"prediction_text\": result[\"answer\"]})\n",
        "    refs.append({\"id\": ex[\"question\"], \"answers\": ex[\"answers\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "0f5126e0aa1c487b94325efa470ae8e2",
            "158d56b6091746fe951b5abc95feabca",
            "1483116418a744dd87caef4c12968888",
            "9e4906f62f93474b93b8bf92722cd67f",
            "de6ff53fb7144dbe86950337fba635c6",
            "485e4fee95d94adda312bf5693f960ec",
            "3b6c80c51b614acca5f8859345c9083e",
            "b2a319a6a9c246b682ad75be2ff7b58b",
            "b2c36f79f9214d07ad4b3c5cf20841df",
            "f31ee16040f2492e87b55eb738851e9c",
            "340604c008e547b59c51fbd6f02f8364",
            "5e3bac6053244fc0b4c9b65fded17028",
            "e3eca73158fd485e93d9625376ad164f",
            "2934fef4a1884063829113c6f1a8df72",
            "55b5befa8ece4a47ac43123b6d356931",
            "3522cdee2fba4483b1a7932508c6e401",
            "c7a595e750d745eb8143b26e6ea8d603",
            "7a915854d5b04ab2889190aaf953de78",
            "0ff1fe21a414409ea8045d73323019e6",
            "5c3834b4eec9477d9d7d3cc88880bfea",
            "84eaa43168884c74bb95147040fbed1d",
            "513bbfe9f27c4aa2b51bd4d0c35d4539"
          ]
        },
        "id": "Z6-HFDWhoxvk",
        "outputId": "3ef5dfb3-a6b4-44d6-c977-e85da759023f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f5126e0aa1c487b94325efa470ae8e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e3bac6053244fc0b4c9b65fded17028"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reformat references to match the expected structure\n",
        "formatted_refs = []\n",
        "for ex in examples[:50]:\n",
        "    # Extract text and answer_start into separate lists\n",
        "    answer_texts = [a['text'] for a in ex['answers']]\n",
        "    answer_starts = [a['answer_start'] for a in ex['answers']]\n",
        "    formatted_refs.append({\"id\": ex[\"question\"], \"answers\": {\"text\": answer_texts, \"answer_start\": answer_starts}})\n",
        "\n",
        "eval_results = metric.compute(predictions=preds, references=formatted_refs)\n",
        "\n",
        "print(\"\\n--- Evaluation ---\")\n",
        "print(f\"Exact Match (EM): {eval_results['exact_match']:.2f}\")\n",
        "print(f\"F1 Score: {eval_results['f1']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdGj3oKLpMVk",
        "outputId": "a49c430f-0d92-4c92-d868-a49e4ca36e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation ---\n",
            "Exact Match (EM): 84.00\n",
            "F1 Score: 85.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bouns Task 6**"
      ],
      "metadata": {
        "id": "OzPm7MdF0A8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Compare Different Models**"
      ],
      "metadata": {
        "id": "ZmFrPvjn0Km0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import kagglehub\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "import evaluate\n",
        "# import streamlit as st\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV8DSdUe1o_B",
        "outputId": "6fca6051-7cd1-48d7-884f-bff184dd1e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_names = [\n",
        "    \"distilbert-base-uncased-distilled-squad\",   # small baseline\n",
        "    \"bert-large-uncased-whole-word-masking-finetuned-squad\",  # BERT\n",
        "    \"deepset/roberta-base-squad2\",               # RoBERTa\n",
        "    \"twmkn9/albert-base-v2-squad2\"               # ALBERT\n",
        "]"
      ],
      "metadata": {
        "id": "nqu75Wfg0E6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluate Models**"
      ],
      "metadata": {
        "id": "iMC_NO182geU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_summary = []\n",
        "\n",
        "for name in model_names:\n",
        "    print(f\"\\nLoading model: {name}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(name)\n",
        "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "    # Evaluate on first 30 examples for speed\n",
        "    preds = []\n",
        "    formatted_refs = []\n",
        "    for ex in examples[:30]:\n",
        "        result = qa_pipeline(question=ex[\"question\"], context=ex[\"context\"])\n",
        "        preds.append({\"id\": ex[\"question\"], \"prediction_text\": result[\"answer\"]})\n",
        "        # format refs\n",
        "        answer_texts = [a['text'] for a in ex['answers']]\n",
        "        answer_starts = [a['answer_start'] for a in ex['answers']]\n",
        "        formatted_refs.append({\"id\": ex[\"question\"], \"answers\": {\"text\": answer_texts, \"answer_start\": answer_starts}})\n",
        "\n",
        "    eval_results = metric.compute(predictions=preds, references=formatted_refs)\n",
        "    print(f\"Exact Match: {eval_results['exact_match']:.2f}, F1: {eval_results['f1']:.2f}\")\n",
        "\n",
        "    results_summary.append({\"model\": name, \"EM\": eval_results['exact_match'], \"F1\": eval_results['f1']})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982,
          "referenced_widgets": [
            "7f0c237ee8a14cdf88c40e807fdb672b",
            "3e84152e93c64ff48615df9d105230df",
            "81e63d760dab4bfdad55483632ea8f02",
            "e54a25f0c28c42629806f1096f72eb63",
            "14113374d7fb4c028e67e0c9f36b9e1d",
            "c84f22f2e56844b791ab11d766c1db97",
            "cf736b13fab94b3389e135205d7619f7",
            "3db4adc865804bcf9756803703ad2205",
            "ef4ac4fee5ad40edb7a74b1c96fd338d",
            "0d068339bf3d420f9a2ca8fcde8df168",
            "58bb59129cc24f408b5591a11d21dd38",
            "058af84a568840a7b0c271091a5c25c0",
            "49509f2117dd44029051120014fe3f09",
            "e26c7eb93c9c4e93b48df38273dd83d8",
            "30c3f4a5e689464690528a897a4672d7",
            "71a44b221f094eb989d4ead9fa0ee15f",
            "e72d005475d942f881ae0806072c58e0",
            "7258090e1c614194a4570886ae57ec6d",
            "559a6d0ca85546549ac2ffaf5c4efa5a",
            "8c79c09468324ca8b76080e5ffcde33e",
            "7f29f397a540415a9f40116c944f0f53",
            "a8a65092134445ee86fc451762873ca0",
            "0adc5c662983474daf702699d69c02ec",
            "950b50147ffc452299fb4f2de3351ade",
            "dda85ed9fcb54ad99439058b60806153",
            "f6d75e2da1e14e969e10883d6895114b",
            "2836365d880a4142926451013ea279cc",
            "0d69555deab94d379772396522d8d8e1",
            "e4568de74fcf49a0be762b3af222c833",
            "7095f90d82f747318d3a7e0218bb8620",
            "236b7136833d49cda184eeaf88c2b94b",
            "c868c7f3f063491ca69ea8888ca3b815",
            "2a0b8f47b1d742e3b79884e529e1cad9",
            "8df93e6134e44c739db175d9b40031b7",
            "b23e840000f04daab19ad193ee3772c9",
            "740ac6609c054b20a181d5ef0f840c71",
            "37761359fa664e88875dff7655138822",
            "18a36f871db847ca999ebb34ef5d1ab6",
            "6e0bd40b5ebd465381d5e84fc39decfc",
            "dcefdc137a1c460c8879e325a90565f7",
            "9ee9c3c2c2dd4f159c68d61e657d5594",
            "84ff6c4b4b2145bfba9b4e761c2bdbde",
            "6e6c34340dae4aeca4493f7d35923081",
            "6f3df751721d4aa78ac5d6a24796f318",
            "37ff629e08ed4281be98d434d4a8aeb6",
            "782011b12ef4444895b59fd17982cba9",
            "845e996f9ab349df96388a3198be45b2",
            "b761bb2f852a4545a0a19cedd8d79f25",
            "97c0f414beb64074996bd89e84f04abf",
            "a6043d1eaba6439fafd4b6aa3e836ce1",
            "4c8a9c0b26904be4a7b82d422049cfbb",
            "b4a3d8c353d34facb4cbdf67c2ca7d1e",
            "9bf5043066034522b46f9ca4618bdd7b",
            "e17059daa1764fef931ffa1ace50ac0b",
            "414bdfc3798742f6a9736759c2e1e2dc",
            "a90e4df0657b4bc3ad9c431ec047fb5c",
            "5afc1877dbcd471cbe7b1b81d8bce522",
            "5560bbbb75d14fe5b2b3f32674108086",
            "375f4262c9a74f89b6c631b78d693ef8",
            "7d14cc12ecbc4b77ba5a802adae00aa0",
            "7773c912785f45178709581785ef391b",
            "16a6378aa9eb4f999a3cc35486ff7855",
            "c5d2f0ba180e4accb8a982c159e8865e",
            "c7b7e48582ca40e2b3bec819e30b7f6f",
            "e6368e0efced40a09e7c3e86dd9efbf2",
            "c89d1ac6006445319367bb3d154c4c82",
            "45b1becec20f4b7f90983aa03de0d429",
            "b3f197a42eeb4e5aa35079f6a4a3d80d",
            "2347ce89ef9744769554e8fce8c23d82",
            "b71f4cda819249aa8838c8154136daa9",
            "b67bfeae60744925b5ba2c33904a6250",
            "9f9821335f8e47dd8448a61bb548d1ea",
            "5418c589c20248719365e390122d9c90",
            "2f37473baba84cbab6bdc088b06d94b2",
            "72536bb80d5344c690df4cec526ee46e",
            "58aaee2111e0455794c0d5688e6d971e",
            "9d6f92bf261544599d6eb88af07f3104",
            "6d564d96fb52467a82d9a4b586a9f0ae",
            "60e297b000a84dd790571e541aa895fd",
            "46daf650abc14d0ebe8c093f95d79190",
            "8ca6aa5e592e4588916ba5a20567c6f5",
            "f895423bb2f142d59071ce6463afcddc",
            "87a7bbef6bb4420699fa7c0ddaf2377c",
            "29ade515df2a4273a74fb026626edab1",
            "43a7d5a0745c4d9a8242c92be4aeb544",
            "2b1a88df0fbd4f87abeb8550f561e363",
            "ba403379d8ca47e7ac212f4120cde15f",
            "b283ab37986446778f4832382e9c4e07",
            "522e1c7176344d348f2f87681bf44f81",
            "2240922d3acf4f93b517fda2f0a9ccd6",
            "970e9d30f9dd4d6ea1c95dc0b858dafa",
            "a1256faab721444fb4753700b75ed23c",
            "c78648f7473846b29205a3d0808f2703",
            "4452d816bcaf49d095d32f3ed9917fda",
            "bfa981edf3aa4eebb92180406d96c8f9",
            "c2f0b69d9db34ef48dbf5cf73f094fcd",
            "89431de7a6dd43779615c14dd038bce1",
            "bf90cbbc79ad46ff8975dd800a524079",
            "13552c01f070408e8ed4e875c763695e",
            "0151a41dd8c1401baada409a3cf0c71c",
            "d460f122cac34ca196e967aa5ae02d90",
            "8e16c4dde6d54cc5bdc3aa861c083f0f",
            "bf993158ed144d419b6cff220e45946c",
            "01e0485bfe6e4eac838c56dd879ecb0c",
            "c907f6992dce447f9ab22375fee2efc2",
            "c5abde02477048489554cda97074d739",
            "7e17714dd93a4f9a9894c929f6185f09",
            "3e8f79bfbd5545419678dfeff3502d37",
            "27af59b50dec449397ed346580a362e8",
            "e5d05ab6267843408aabb94bbe3cdb3a",
            "de8bada81add49c38a7c3f32889179cc",
            "3516daee62034f44a76c8c1c2e0b0970",
            "a394e5a86a894a84a0b6efa5e5832175",
            "1fb7f657d788450899931648c68b4864",
            "88dad4bfe7a54ddb924e746466aeb652",
            "19a2b812c99a4667b0e1955bb130876e",
            "87110c2e11bb4da486dfc978ed30ac9c",
            "f94a4c7a056644168d3b703e61545096",
            "43f7205b471545049ff5b5fbb3ff6ff6",
            "b63374dc72a04d049c8035183131a982",
            "6dbd65104a2b44d88b726d52b15c1aed",
            "66893d2bdfbb4997930904f5decf9022",
            "04e0f07402964292a2d35e37f4ccf1d7",
            "e818b217b4c4460ca3928a312ce45b53",
            "5fcf0fa19e7c4b2497d17f53aca6f7c5",
            "da063bafd0264f0a986ddd9837e75116",
            "574ef1f08be44fb2be4ec6480c4ac5e6",
            "d3d18acad7e94b56b01935ffe4c8d0c7",
            "d16549057f424e9cabb1dff3749409ec",
            "58c4abfb7d924db482acfbc8a063e133",
            "1b91479a438943a98e9460670d7e1b9b",
            "b2469723cf6145818c586eca9876ec3d",
            "96a1a185d9aa4452999d9645eb0a0792",
            "cdb49fc0b2cd4bfe90f140e668f9b29d",
            "b01d3a9428794a9a9a860eca93a4ce05",
            "31325851ecd54d49805de4d705749472",
            "32d54e8fe62c4998ade8436900445fb9",
            "fe399d388c654868b92d63abfd10506b",
            "7cc09c80642c4fd2a3cbe6ae31b31f3b",
            "a0046f0c09604ccc9504ba4556921e81",
            "836fb0cf9fd04f798a378dd7e4c4693b",
            "4b68f3164c4b4b599e7def54aa209499",
            "172ab4a41b0e41c5b08fa233dd340f6e",
            "fbe3448fb8c44bbda0dc632c933cc71c",
            "edd7eba0d064404bbc99ed98762e1312",
            "fcdfa22844b94f13874d4899208de41d",
            "b24170be073b4f5ab0b5dd69b0767e8f",
            "39d819f00cc54a8bbdcceb5bc0d92fbf",
            "b1bca65245dd4fb8a1135b1a65726aa5",
            "3c1ede4783374c79a8b00c08a0c2ba70",
            "acb4ac4a6fea48d5abbf196791610cb6",
            "4f66b1282ebd408fa7348ec6bed694d4",
            "3e588ab31f4f4d54b8d888d636234086",
            "5a7acfdcf9a3471e87056812348c4419",
            "44509a092fc54e088c2690dcfd441c84",
            "c516f6050b3d49adbf3168cfa0238cc7",
            "6b65225ecff74ed2825dee9a670c08bd",
            "7d9b5f6f0e2a4762bd2aca2321eef118",
            "6f05c8a3032e472bb02c2100719d4907",
            "deea2aa9ad0a471186cec21087d25a5d",
            "758f5bac160047f4aa474c69faeecce8",
            "dfd2f8a3be7a4c4fbc61133bb52ae4ed",
            "a24b1eec836c403d913e58f2dfaeb73f",
            "c6456d3f0a26400ab03b3240d7819aff",
            "d52695d5563249a2afaa26bf96ebc003",
            "f09c64801b3d4c3f88d61daec0da764f",
            "65c7c7759ba64cab9a82b10c92d7b728",
            "55e65dfbf0e54a4b8bee122cca7cbfe2",
            "e3c6f08c6ae84cab85b1a1e1dd06b5b6",
            "d1fdd25a36f049c0b2cdb32e9c6e7e25",
            "67eecd6af2784cad9e39c71c08f620f7",
            "df50b7e39a8f49758591732a0009f67d",
            "99bc6671d3b54eb5a961c9d3ec4fe854",
            "b7f2ec7c10ce4470aa8e58bd82f88e9a",
            "2f305a3e33c140e287752bca3634cc18",
            "caaa6dc399e0479b8934ae2e11e633c2",
            "98df7703b2b442f1acc936b9598d0cb3",
            "be5b92b1db9949c4b58d8545afbbdeac",
            "d438e8e68bea487894b0ce9c2b45c427",
            "66d3be43dee449bdb1745aa8a0e1d1f6",
            "8d83057b5368474fa02970f6d9c8a56e",
            "8069aeba3d744617b51174fb6e00dcac",
            "0d9f1b182d1341949039b42e0c3e8368",
            "a709989df0854d2493376b25e13af0db",
            "27d432b7178646b39b7356ea2475be32",
            "51d977ec369f460c8c6f0a7613150055",
            "9283f9d0607e411199326c936350e32f"
          ]
        },
        "id": "lHccW2Wi11MF",
        "outputId": "b72917c5-0bfb-4f54-abd6-37f4983d9862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading model: distilbert-base-uncased-distilled-squad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match: 90.00, F1: 92.67\n",
            "\n",
            "Loading model: bert-large-uncased-whole-word-masking-finetuned-squad\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f0c237ee8a14cdf88c40e807fdb672b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "058af84a568840a7b0c271091a5c25c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0adc5c662983474daf702699d69c02ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8df93e6134e44c739db175d9b40031b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37ff629e08ed4281be98d434d4a8aeb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match: 86.67, F1: 96.10\n",
            "\n",
            "Loading model: deepset/roberta-base-squad2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a90e4df0657b4bc3ad9c431ec047fb5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45b1becec20f4b7f90983aa03de0d429"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d564d96fb52467a82d9a4b586a9f0ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "522e1c7176344d348f2f87681bf44f81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0151a41dd8c1401baada409a3cf0c71c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de8bada81add49c38a7c3f32889179cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match: 93.33, F1: 97.43\n",
            "\n",
            "Loading model: twmkn9/albert-base-v2-squad2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66893d2bdfbb4997930904f5decf9022"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/716 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96a1a185d9aa4452999d9645eb0a0792"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbe3448fb8c44bbda0dc632c933cc71c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44509a092fc54e088c2690dcfd441c84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f09c64801b3d4c3f88d61daec0da764f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at twmkn9/albert-base-v2-squad2 were not used when initializing AlbertForQuestionAnswering: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/46.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98df7703b2b442f1acc936b9598d0cb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match: 76.67, F1: 79.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Model Comparison Summary ---\")\n",
        "for r in results_summary:\n",
        "    print(f\"{r['model']}: EM={r['EM']:.2f}, F1={r['F1']:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YokSPPCs0Qsf",
        "outputId": "29788862-af78-45fe-e80c-9d30668202a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Comparison Summary ---\n",
            "distilbert-base-uncased-distilled-squad: EM=90.00, F1=92.67\n",
            "bert-large-uncased-whole-word-masking-finetuned-squad: EM=86.67, F1=96.10\n",
            "deepset/roberta-base-squad2: EM=93.33, F1=97.43\n",
            "twmkn9/albert-base-v2-squad2: EM=76.67, F1=79.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Simple Streamlit Interface**"
      ],
      "metadata": {
        "id": "m83_2wTH0fvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **Command-line Interface**\n",
        "while True:\n",
        "    context = input(\"\\nEnter a passage (or 'quit' to stop): \")\n",
        "    if context.lower() == \"quit\":\n",
        "        break\n",
        "    question = input(\"Enter your question: \")\n",
        "\n",
        "    # Use the best performing model (e.g., RoBERTa)\n",
        "    model_name = \"deepset/roberta-base-squad2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "    qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "    result = qa_pipeline(question=question, context=context)\n",
        "    print(f\"Answer: {result['answer']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjgg-uuK0cdm",
        "outputId": "93f6ba0c-9fa2-4ada-ea0d-59040be70d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Enter a passage (or 'quit' to stop): Albert Einstein was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics. His work is also known for its influence on the philosophy of science.\n",
            "Enter your question: Who developed the theory of relativity?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Albert Einstein\n",
            "\n",
            "Enter a passage (or 'quit' to stop): Albert Einstein was a German-born theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics. His work is also known for its influence on the philosophy of science.\n",
            "Enter your question: What was Einstein's contribution to physics?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: developed the theory of relativity\n",
            "\n",
            "Enter a passage (or 'quit' to stop): stop\n",
            "Enter your question: stop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: stop\n",
            "\n",
            "Enter a passage (or 'quit' to stop): quit\n"
          ]
        }
      ]
    }
  ]
}